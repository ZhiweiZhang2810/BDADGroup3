{
  "metadata": {
    "name": "TLC ML",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val df \u003d spark.read.option(\"header\", \"true\").parquet(\"/user/qz2166_nyu_edu/tlc_trip_data/yellow_taxi_ml_clean.parquet\");\n\nval Array(trainDf, testDf) \u003d df.randomSplit(Array(0.8, 0.2), seed\u003d64)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n\nval categoricalCols \u003d trainDf.dtypes.filter(_._2 \u003d\u003d \"StringType\").map(_._1)\nval indexOutputCols \u003d categoricalCols.map(_ + \"_index\")\nval oheOutputCols \u003d categoricalCols.map(_ + \"_OHE\")\n\nval stringIndexer \u003d new StringIndexer()\n  .setInputCols(categoricalCols)\n  .setOutputCols(indexOutputCols)\n  .setHandleInvalid(\"skip\")\n\nval oheEncoder \u003d new OneHotEncoder()\n  .setInputCols(indexOutputCols)\n  .setOutputCols(oheOutputCols)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.VectorAssembler\n\nval numericCols \u003d trainDf.dtypes.filter{\n  case (field, dataType) \u003d\u003e dataType !\u003d \"StringType\" \u0026\u0026 field !\u003d \"tip_amount\"\n}.map(_._1)\nval assemblerInputs \u003d oheOutputCols ++ numericCols\nval vecAssembler \u003d new VectorAssembler()\n  .setInputCols(assemblerInputs)\n  .setOutputCol(\"features\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.regression.LinearRegression\n\nval lr \u003d new LinearRegression()\n  .setLabelCol(\"tip_amount\")\n  .setFeaturesCol(\"features\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.Pipeline\n\nval pipeline \u003d new Pipeline()\n  .setStages(Array(stringIndexer, oheEncoder, vecAssembler, lr))\n\nval pipelineModel \u003d pipeline.fit(trainDf)\nval predDF \u003d pipelineModel.transform(testDf)\nz.show(predDF.select(\"features\", \"tip_amount\", \"prediction\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.evaluation.RegressionEvaluator\n\nval regressionEvaluator \u003d new RegressionEvaluator()\n  .setPredictionCol(\"prediction\")\n  .setLabelCol(\"tip_amount\")\n  .setMetricName(\"rmse\")\n\nval rmse \u003d regressionEvaluator.evaluate(predDF)\nprintln(f\"RMSE is $rmse%1.2f\")\n\nval r2 \u003d regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\nprintln(f\"R2 is $r2%1.2f\")"
    }
  ]
}